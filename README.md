# Image-Classification-of-American-Sign-Language-Dataset

This is a deep learning image classification using a CNN model to recognize American Sign Language (ASL) hand signs.

Developed in Python using PyTorch on Google Colab.

## Project Overview
- **Dataset:** American Sign Language images (grayscale, provided by instructor)
- **Model:** Convolutional Neural Network (CNN) ith 3 convolutional blocks and dropout regularization
- **Packages:** 'PyTorch', 'Torchvision', 'NumPy', 'Matplotlib'

## Model Accuracy
- **Training accuracy:** 99.83%
- **Validation accuracy:** 99.29%

## File Overview
- ['STA138_Final_Project_json.ipynb'](myLib/STA138_Final_Project_json.ipynb): Full code and model structure
- ['STA138 Final Project LS.pdf'](myLib/STA138_Final_Project_LS.pdf): Output summary (code and result combined)
- ['Log LS.txt'](myLib/Log_LS.txt): Training and validation accuracy logs

## Attribution

This project was completed as part of an individual assignment for **STA138 (Analysis of Categorical Data)** at UC Davis.
